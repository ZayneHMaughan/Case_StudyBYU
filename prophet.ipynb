{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.utilities import regressor_coefficients\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from neuralprophet import NeuralProphet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_33400\\827163187.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  holidays['lower_window'] = -7\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_33400\\827163187.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  holidays['upper_window'] = 7\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_33400\\827163187.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  holidays['ds'] = pd.to_datetime(holidays['ds'], format=\"%Y-%m-%d\")\n"
     ]
    }
   ],
   "source": [
    "day_data = pd.read_csv('../day_data.csv')\n",
    "day_data = day_data.rename(columns={'date': 'ds'})\n",
    "day_data['ds'] = pd.to_datetime(day_data['ds'], format=\"%Y-%m-%d\")\n",
    "day_data = day_data[day_data['ds'] < '2024-02-01']\n",
    "\n",
    "holidays = day_data[['ds', 'holiday']]\n",
    "holidays['lower_window'] = -7\n",
    "holidays['upper_window'] = 7\n",
    "holidays['ds'] = pd.to_datetime(holidays['ds'], format=\"%Y-%m-%d\")\n",
    "calendar = holidays\n",
    "calendar = calendar[~calendar['holiday'].isnull()]\n",
    "\n",
    "start_date = day_data['ds'].min()\n",
    "end_date = '2024-01-31'\n",
    "all_dates = pd.DataFrame(\n",
    "    data=pd.date_range(start_date, end_date, freq='d'),\n",
    "    columns=['ds']\n",
    ")\n",
    "all_dates['ds'] = pd.to_datetime(all_dates['ds'], format=\"%Y-%m-%d\")\n",
    "\n",
    "day_data = day_data.drop(columns=['holiday'])\n",
    "regressor_columns = ['moon', 'arrest', 'wd']\n",
    "output_data = pd.merge(\n",
    "    all_dates[all_dates['ds'] >= day_data['ds'].min()], \n",
    "    day_data, \n",
    "    how='left', \n",
    "    on=['ds'])\n",
    "output_data.sort_values(\n",
    "    by=['ds'], \n",
    "    ascending=True, \n",
    "    inplace=True, \n",
    "    ignore_index=True)\n",
    "\n",
    "input_data = day_data.rename(columns={'num_crimes': 'y'})\n",
    "enc = OneHotEncoder(drop='first')\n",
    "wd_enc = enc.fit_transform(input_data[['wd']])\n",
    "wd_enc = wd_enc.toarray()\n",
    "wds = enc.get_feature_names_out(['wd'])\n",
    "wd_enc = pd.DataFrame(wd_enc, columns=wds)\n",
    "input_data = pd.concat([input_data, wd_enc], axis=1)\n",
    "input_data = input_data.drop(columns=['wd'])\n",
    "input_data = input_data[input_data['ds'] < '2024-01-01']\n",
    "\n",
    "output_data = output_data.rename(columns={'num_crimes': 'y'})\n",
    "wd_enc = enc.fit_transform(output_data[['wd']])\n",
    "wds = enc.get_feature_names_out(['wd'])\n",
    "wd_enc = wd_enc.toarray()\n",
    "wd_enc = pd.DataFrame(wd_enc, columns=wds)\n",
    "output_data = pd.concat([output_data, wd_enc], axis=1)\n",
    "output_data = output_data.drop(columns=['wd'])\n",
    "\n",
    "proph = Prophet(\n",
    "    holidays=calendar,\n",
    "    yearly_seasonality=True,\n",
    "    seasonality_mode='multiplicative',\n",
    "    holidays_prior_scale=0.05,\n",
    "    changepoint_prior_scale=0.05,\n",
    "    uncertainty_samples=50)\n",
    "\n",
    "regressors = ['moon', 'arrest', 'wPC1', 'wPC2', 'wPC3']\n",
    "for r in regressors:\n",
    "    proph.add_regressor(r)\n",
    "input_data = input_data[['ds', 'y', 'moon', 'arrest', 'wPC1', 'wPC2', 'wPC3']]\n",
    "proph.fit(input_data)\n",
    "forecast = proph.predict(output_data)\n",
    "\n",
    "# pred accuracy\n",
    "preds = forecast[forecast['ds'] > '2023-12-31']['yhat']\n",
    "y_real = output_data[output_data['ds'] > '2023-12-31']['y']\n",
    "print(f' mse: {mean_squared_error(y_real, preds)}')\n",
    "print(f' rmse: {root_mean_squared_error(y_real, preds)}')\n",
    "\n",
    "# plots\n",
    "for_plot = proph.plot(forecast)\n",
    "a = add_changepoints_to_plot(for_plot.gca(), proph, forecast)\n",
    "comps = proph.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regressor</th>\n",
       "      <th>regressor_mode</th>\n",
       "      <th>center</th>\n",
       "      <th>coef_lower</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moon</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.039901</td>\n",
       "      <td>-0.039901</td>\n",
       "      <td>-0.039901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrest</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.372632</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.289941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wPC1</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>-0.032090</td>\n",
       "      <td>-0.032090</td>\n",
       "      <td>-0.032090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wPC2</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>-0.005754</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wPC3</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>-0.028530</td>\n",
       "      <td>0.027305</td>\n",
       "      <td>0.027305</td>\n",
       "      <td>0.027305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regressor  regressor_mode    center  coef_lower      coef  coef_upper\n",
       "0      moon  multiplicative  0.000000   -0.039901 -0.039901   -0.039901\n",
       "1    arrest  multiplicative  0.372632    0.289941  0.289941    0.289941\n",
       "2      wPC1  multiplicative -0.037640   -0.032090 -0.032090   -0.032090\n",
       "3      wPC2  multiplicative -0.005754    0.003034  0.003034    0.003034\n",
       "4      wPC3  multiplicative -0.028530    0.027305  0.027305    0.027305"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_coefficients(proph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.98% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 70\n",
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (80) is too small than the required number                     for the learning rate finder (242). The results might not be optimal.\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Finding best initial lr: 100%|| 242/242 [00:07<00:00, 30.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|| 70/70 [00:02<00:00, 30.47it/s, loss=0.0206, v_num=3, MAE=6.720, RMSE=8.680, Loss=0.0214, RegLoss=0.000]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.981% of the data.\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.981% of the data.\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\neuralprophet\\time_dataset.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  additive_events[key] = offset_feature\n",
      "c:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 6/6 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " mse: 37.057459549559304\n",
      " rmse: 6.087483843884869\n"
     ]
    }
   ],
   "source": [
    "# Neural Prophet\n",
    "\n",
    "moon_df = input_data[input_data['moon'] == 1][['ds']]\n",
    "moon_df['event'] = 'full_moon'\n",
    "calendar_np = calendar[['ds', 'holiday']]\n",
    "calendar_np = calendar_np.rename(columns={'holiday': 'event'})\n",
    "\n",
    "np = NeuralProphet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    seasonality_mode='multiplicative',\n",
    "    n_lags=10,\n",
    "    quantiles=[0.025, 0.975],\n",
    "    learning_rate=0.0001,\n",
    "    epochs=100\n",
    ")\n",
    "np.add_events(\"full_moon\")\n",
    "np.add_country_holidays(\"US\", lower_window=-7, upper_window=7)\n",
    "np.add_lagged_regressor('wPC1', n_lags=3)\n",
    "np.add_lagged_regressor('wPC2', n_lags=3)\n",
    "np.add_lagged_regressor('wPC3', n_lags=3)\n",
    "np.add_lagged_regressor('arrest', n_lags=3)\n",
    "input_all = np.create_df_with_events(input_data, moon_df)\n",
    "input_all = input_all.drop(columns=['moon'])\n",
    "\n",
    "np.fit(input_all)\n",
    "\n",
    "output_data_np = output_data[['ds', 'y', 'arrest', 'wPC1', 'wPC2', 'wPC3']]\n",
    "output_data_np\n",
    "output_all = np.create_df_with_events(output_data_np, moon_df)\n",
    "\n",
    "forecast = np.predict(output_all)\n",
    "\n",
    "# pred accuracy\n",
    "preds = forecast[forecast['ds'] > '2023-12-31']['yhat1']\n",
    "y_real = output_data[output_data['ds'] > '2023-12-31']['y']\n",
    "print(f' mse: {mean_squared_error(y_real, preds)}')\n",
    "print(f' rmse: {root_mean_squared_error(y_real, preds)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "durham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
