{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from math import sqrt\n",
    "import shap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test, :], data[-n_test:, :]\n",
    "\n",
    "def random_forest_forecast(train, testX):\n",
    "    # transform list into array\n",
    "\n",
    "    # split into input and output columns\n",
    "    trainX, trainy = train[:, :-1], train[:, -1]\n",
    "    # fit model\n",
    "    model = RandomForestRegressor(n_estimators=1000)\n",
    "    model.fit(trainX, trainy)\n",
    "    # make a one-step prediction\n",
    "    yhat = model.predict([testX])\n",
    "    return yhat[0]\n",
    "\n",
    "def walk_forward_validation(data, n_test):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # split test row into input and output columns\n",
    "        testX, testy = test[i, :-1], test[i, -1]\n",
    "        # fit model on history and make a prediction\n",
    "        yhat = random_forest_forecast(history, testX)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "        # summarize progress\n",
    "        print('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
    "    # estimate prediction error\n",
    "    error = mean_absolute_error(test[:, -1], predictions)\n",
    "    return error, test[:, -1], predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = pd.read_csv('../day_data.csv')\n",
    "day_data['date'] = pd.to_datetime(day_data['date'], format=\"%Y-%m-%d\")\n",
    "day_data['holiday'] = day_data['holiday'].fillna('0')\n",
    "\n",
    "onehot = OneHotEncoder(categories='auto', drop=None, sparse_output=False)\n",
    "holidays = onehot.fit_transform(day_data[['holiday']])\n",
    "holidays = pd.DataFrame(holidays, columns=onehot.categories_)\n",
    "\n",
    "onehot = OneHotEncoder(categories='auto', drop='first', sparse_output=False)\n",
    "wd = onehot.fit_transform(day_data[['wd']])\n",
    "wd = pd.DataFrame(wd, columns=onehot.get_feature_names_out(['wd']))\n",
    "\n",
    "day_data = pd.concat([day_data, holidays, wd], axis=1)\n",
    "day_data = day_data.drop(columns=['holiday', ('0',), 'wd'])\n",
    "day_data.columns = day_data.columns.astype(str)\n",
    "\n",
    "cutoff_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['x1'] = train_data['num_crimes'].shift(1)\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['x2'] = train_data['num_crimes'].shift(2)\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['x3'] = train_data['num_crimes'].shift(3)\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['x1'] = test_data['num_crimes'].shift(1)\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['x2'] = test_data['num_crimes'].shift(2)\n",
      "C:\\Users\\benke\\AppData\\Local\\Temp\\ipykernel_29284\\2322444573.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['x3'] = test_data['num_crimes'].shift(3)\n"
     ]
    }
   ],
   "source": [
    "train_data = day_data[day_data['date'] < cutoff_date]\n",
    "train_data['x1'] = train_data['num_crimes'].shift(1)\n",
    "train_data['x2'] = train_data['num_crimes'].shift(2)\n",
    "train_data['x3'] = train_data['num_crimes'].shift(3)\n",
    "train_data = train_data.ffill().bfill().ffill()\n",
    "\n",
    "y_train = train_data['num_crimes']\n",
    "train_dates = train_data['date']\n",
    "X_train = train_data.drop(columns=['num_crimes', 'date'])\n",
    "\n",
    "test_data = day_data[(day_data['date'] >= cutoff_date) & (day_data['date'] <= '2024-01-31')]\n",
    "test_data['x1'] = test_data['num_crimes'].shift(1)\n",
    "test_data['x2'] = test_data['num_crimes'].shift(2)\n",
    "test_data['x3'] = test_data['num_crimes'].shift(3)\n",
    "test_data = test_data.ffill().bfill().ffill()\n",
    "y_test = test_data['num_crimes']\n",
    "test_dates = test_data['date']\n",
    "X_test = test_data.drop(columns=['num_crimes', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_forecast(train, X_test):\n",
    "    y_train = train_data['num_crimes']\n",
    "    train_dates = train_data['date']\n",
    "    X_train = train_data.drop(columns=['num_crimes', 'date'])\n",
    "\n",
    "    # fit model\n",
    "    model = RandomForestRegressor(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    # make a one-step prediction\n",
    "    yhat = model.predict(X_test)\n",
    "    return yhat[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.062"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_forecast(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test, :], data[-n_test:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_crimes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pandas\\core\\indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pandas\\core\\indexing.py:1691\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1691\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1693\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pandas\\core\\indexing.py:963\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tuple_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m    960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m    Check the key for valid keys across my indexer.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 963\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(key)\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n",
      "File \u001b[1;32mc:\\Users\\benke\\anaconda3\\envs\\durham\\Lib\\site-packages\\pandas\\core\\indexing.py:1002\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(_one_ellipsis_message)\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m-> 1002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "test_data['num_crimes'].iloc[1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(train_data, test_data):\n",
    "    predictions = []\n",
    "\n",
    "    train = train_data\n",
    "    test = test_data\n",
    "\n",
    "    history = train\n",
    "\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # split test row into input and output columns\n",
    "        y_test = test['num_crimes'].iloc[i]\n",
    "        X_test = test.iloc[i]\n",
    "        X_test = X_test.drop(columns=['num_crimes'])\n",
    "        # fit model on history and make a prediction\n",
    "        yhat = random_forest_forecast(history, X_test)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        pred_row = \n",
    "        history = pd.concat([history, test.iloc[i,:]])\n",
    "        # summarize progress\n",
    "        print('>expected=%.1f, predicted=%.1f' % (y_test, yhat))\n",
    "    # estimate prediction error\n",
    "    error = mean_absolute_error(test[:, -1], predictions)\n",
    "    return error, test[:, -1], predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 32.23210532258064 \n",
      " RMSE: 5.677332588688163\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(\n",
    "    random_state=42, \n",
    "    n_estimators=1000,\n",
    "    )\n",
    "rf_model.fit(X_train, y_train)\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse} \\n RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_forward_validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "durham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
